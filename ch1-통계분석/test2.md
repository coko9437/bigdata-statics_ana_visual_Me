
---

### **Ch1-2 코드 종합 설명**

이 코드는 `seaborn` 라이브러리에 내장된 **타이타닉호 탑승객 데이터**를 사용하여 **생존 여부(`survived`)**와 다른 특성들(성별, 나이, 객실 등급 등) 간의 관계를 분석합니다. 주요 목표는 어떤 요인이 생존에 큰 영향을 미쳤는지 파악하는 것입니다.

1.  **데이터 준비 및 전처리:** 데이터를 불러온 뒤, 분석에 방해가 되는 **결측치(Null 값)**를 찾아냅니다. `age`는 **중앙값**으로, `embarked`와 `deck` 등은 **최빈값**(가장 빈번하게 나타나는 값)으로 채워 넣어 데이터를 정제합니다.
2.  **탐색적 데이터 분석 (EDA):** `matplotlib`과 `seaborn`을 이용해 **파이 차트**와 **카운트 플롯**을 그려 성별, 객실 등급에 따른 생존율의 차이를 시각적으로 탐색합니다.
3.  **상관 분석 및 피처 엔지니어링:** `pandas`의 `corr()` 함수를 사용해 모든 숫자형 변수 간의 **피어슨 상관계수**를 계산합니다. 또한, 분석의 정확도를 높이기 위해 기존 변수들을 가공하여 `age2`(나이대), `family`(가족 수)와 같은 새로운 **파생 변수**를 만드는 **피처 엔지니어링**을 수행합니다.
4.  **시각화 (히트맵):** 최종적으로 계산된 상관계수 행렬을 **히트맵**으로 시각화하여, 어떤 변수들이 생존 여부와 강한 양 또는 음의 관계를 가지는지 한눈에 파악하고 결론을 도출합니다.

---

### **Part 1: 데이터 수집 및 전처리 (결측치 처리)**

어떤 분석이든 가장 먼저 수행해야 할, 데이터를 깨끗하게 만드는 과정입니다.

#### **1. 코드, 문법 및 개별 설명**

```python
# %%
import seaborn as sns
import pandas as pd

# Seaborn에 내장된 'titanic' 데이터셋을 불러옴
titanic = sns.load_dataset("titanic")

# 데이터의 결측치(null) 개수를 컬럼별로 확인
titanic.isnull().sum()
# 결과값 (예시):
# age            177  -> 177개의 나이 정보가 비어있음
# embarked         2
# deck           688  -> 688개의 deck 정보가 비어있음
# embark_town      2
# ... (다른 컬럼은 0)

# 'age' 컬럼의 결측치를 'age'의 중앙값으로 채움
# 연산 과정:
# 1. titanic['age'].median()으로 나이의 중앙값(예: 28.0)을 계산
# 2. .fillna() 함수가 'age' 컬럼에서 null인 값들을 찾아 28.0으로 대체
titanic['age'] = titanic['age'].fillna(titanic['age'].median())

# 'embarked', 'deck', 'embark_town' 컬럼의 최빈값을 확인
# .value_counts()는 각 값의 개수를 세어 내림차순으로 보여줌
print(titanic["embarked"].value_counts())  # 결과: S가 644로 가장 많음
print(titanic["deck"].value_counts())      # 결과: C가 59로 가장 많음 (주석과 달리 C가 최빈값)
print(titanic["embark_town"].value_counts()) # 결과: Southampton이 644로 가장 많음

# 각 컬럼의 결측치를 해당 컬럼의 최빈값으로 채움
titanic["embarked"] = titanic["embarked"].fillna("S")
titanic["deck"] = titanic["deck"].fillna("C") # 'C'가 실제 데이터의 최빈값
titanic["embark_town"] = titanic["embark_town"].fillna("Southampton")

# 모든 결측치가 처리되었는지 다시 확인
titanic.isnull().sum()
# 결과: 모든 컬럼의 결측치 개수가 0으로 표시됨
```

#### **2. 해당 설명**

"Garbage in, garbage out" (쓰레기를 넣으면 쓰레기가 나온다)는 데이터 분석의 유명한 격언입니다. 분석의 신뢰도는 데이터의 품질에 달려있기 때문에, **결측치 처리**는 매우 중요한 첫 단계입니다. 위 코드에서는 두 가지 대표적인 결측치 대체 방법을 사용했습니다.

*   **중앙값(Median) 대체:** `age`와 같은 숫자형 데이터에 사용됩니다. 평균(mean)은 극단적인 값(아주 늙거나 어린 나이)에 영향을 많이 받지만, 중앙값은 상대적으로 안정적이라 이상치(outlier)가 있을 때 더 좋은 선택입니다.
*   **최빈값(Mode) 대체:** `embarked`(탑승 항구)와 같은 범주형 데이터에 사용됩니다. 가장 많이 등장한 값으로 채우는 것이 가장 합리적인 추정이기 때문입니다.

#### **3. 응용 가능한 예제**

**"온라인 쇼핑몰 고객 데이터의 누락된 '가입 경로' 정보 채우기"**

고객 데이터에 '가입 경로'(예: 'Google 검색', '인스타그램 광고', '지인 추천') 정보가 일부 누락되었을 때, 전체 데이터에서 가장 빈번한 가입 경로(최빈값)를 찾아 누락된 값을 채워넣어 마케팅 분석의 정확도를 높일 수 있습니다.

#### **4. 추가하고 싶은 내용 (결측치 삭제)**

결측치를 채우는 대신, 해당 행 전체를 삭제하는 방법(`dropna()`)도 있습니다. 이는 결측치가 있는 데이터의 양이 전체에 비해 매우 적을 때(예: 1% 미만) 간단하게 사용할 수 있습니다. 하지만 `deck` 컬럼처럼 결측치가 너무 많을(688/891, 약 77%) 경우, 해당 컬럼 자체를 분석에서 제외하는 것(`drop()`)이 더 나은 판단일 수 있습니다.

#### **5. 심화 내용 (결측치 자체의 의미)**

때로는 데이터가 **'왜 비어있는가'** 자체가 중요한 정보일 수 있습니다. 예를 들어, 타이타닉 데이터에서 `deck` 정보가 없는 사람들은 애초에 객실을 배정받지 못한 하층민일 가능성이 높습니다. 따라서 무작정 최빈값으로 채우기보다는, 'Deck_Unknown'이라는 새로운 카테고리를 만들거나, 결측치 여부 자체를 하나의 변수(예: `has_deck_info` = 0 또는 1)로 만들어 분석에 활용하는 고급 기법도 존재합니다.

---

### **Part 2: 탐색적 데이터 분석(EDA) 및 기본 시각화**

데이터를 정제한 후, 본격적인 분석에 앞서 데이터의 특징을 시각적으로 살펴보는 과정입니다.

#### **1. 코드, 문법 및 개별 설명**

```python
# %%
import matplotlib.pyplot as plt
import seaborn as sns

# 1행 2열의 서브플롯(그래프 그릴 공간)을 생성. 전체 크기는 가로 10, 세로 5
f, ax = plt.subplots(1, 2, figsize=(10, 5))

# 남성 생존율 파이 차트 (왼쪽)
# 연산 과정:
# 1. titanic["sex"] == 'male' : 성별이 남성인 행들만 필터링
# 2. titanic['survived'][...] : 필터링된 행들에서 'survived' 열만 선택
# 3. .value_counts() : 남성의 생존(1)/사망(0)자 수를 각각 계산
# 4. .plot.pie(...) : 계산된 값을 파이 차트로 그림. autopct는 백분율 표시 형식, ax=ax[0]는 왼쪽 공간에 그리라는 의미
titanic['survived'][titanic["sex"] == 'male'].value_counts().plot.pie(explode=[0, 0.1], autopct="%1.1f%%", ax=ax[0], shadow=True)

# 여성 생존율 파이 차트 (오른쪽)
titanic['survived'][titanic["sex"] == 'female'].value_counts().plot.pie(explode=[0, 0.1], autopct="%1.1f%%", ax=ax[1], shadow=True)

# 각 차트의 제목 설정
ax[0].set_title("Survived (male)")
ax[1].set_title("Survived (female)")
plt.show()

# 객실 등급(pclass)별 생존자/사망자 수를 막대그래프로 시각화
# 연산 과정:
# 1. x="pclass": x축을 객실 등급으로 설정
# 2. hue="survived": 'survived' 값(0 또는 1)에 따라 막대 색을 다르게 표현
# 3. data=titanic: 사용할 데이터프레임을 지정
sns.countplot(x="pclass", hue="survived", data=titanic)
plt.title("Pclass vs Survived")
plt.show()
# 결과 해석:
# 파이 차트 -> 여성의 생존율(약 74.2%)이 남성(약 18.9%)보다 압도적으로 높음을 확인.
# 카운트 플롯 -> 1등급 객실은 생존자 수가 사망자 수보다 많지만, 3등급 객실은 사망자 수가 압도적으로 많음을 확인.
```

#### **2. 해당 설명**

이 파트에서는 **성별**과 **객실 등급**이 생존율에 큰 영향을 미쳤을 것이라는 가설을 세우고, 이를 시각적으로 빠르게 확인합니다. **파이 차트**는 전체 대비 각 부분의 비율을 보여주는 데 효과적이며, 이를 통해 남성과 여성의 생존율이 극명하게 갈렸음을 즉시 알 수 있습니다. **카운트 플롯(`countplot`)**은 범주형 데이터의 개수를 세어 막대그래프로 보여주는 `seaborn`의 유용한 함수로, 객실 등급이 낮아질수록 사망자 수가 급격히 늘어나는 패턴을 명확하게 보여줍니다.

#### **3. 응용 가능한 예제**

**"요일 및 시간대별 카페 메뉴 판매량 분석"**

`countplot`을 이용해 x축을 '요일', `hue`를 '메뉴 카테고리(커피/논커피)'로 설정하여 어떤 요일에 어떤 종류의 음료가 많이 팔리는지 시각화하고, 이를 통해 재고 관리 및 프로모션 전략을 수립할 수 있습니다.

#### **4. 추가하고 싶은 내용 (Box Plot 활용)**

`countplot` 외에도 `boxplot`이나 `violinplot`을 사용하면 범주에 따른 숫자 데이터의 분포를 더 상세하게 볼 수 있습니다. 예를 들어, `sns.boxplot(x='survived', y='age', data=titanic)` 코드를 실행하면 생존자와 사망자의 나이 분포(중앙값, 사분위수, 이상치 등)를 비교하여 '어린 아이들이 더 많이 살았는가?'와 같은 질문을 탐색할 수 있습니다.

#### **5. 심화 내용 (통계적 유의성 검증)**

시각화를 통해 발견한 차이가 우연인지 통계적으로 의미가 있는 것인지 확인하려면 **카이제곱 검정(Chi-squared test)**을 사용할 수 있습니다. `성별`과 `생존여부` 같은 두 범주형 변수 간의 독립성(관련이 있는지 없는지)을 검증하는 데 사용되며, "성별과 생존율은 통계적으로 유의미한 관계가 있다"는 결론을 수치적으로 뒷받침할 수 있습니다.

---

### **Part 3: 상관 분석 및 피처 엔지니어링**

데이터 간의 수치적 관계를 정량화하고, 더 나은 분석을 위해 새로운 특징(Feature)을 만들어내는 과정입니다.

#### **1. 코드, 문법 및 개별 설명**

```python
# %%
import numpy as np

# 상관계수 계산을 위해 데이터프레임에서 숫자형(numeric) 컬럼만 선택
numeric_titanic = titanic.select_dtypes(include=[np.number])

# 숫자형 데이터 간의 피어슨 상관계수 행렬을 계산
titanic_corr = numeric_titanic.corr(method='pearson')
print(titanic_corr)

# 'survived'와 'adult_male' 사이의 상관계수만 별도로 계산
# adult_male은 True/False 값을 가지므로, 계산 시 1/0으로 자동 변환됨
adult_male_corr = titanic["survived"].corr(titanic["adult_male"])
# 결과: -0.557728 -> 성인 남성일수록 생존율이 낮아지는 강한 음의 상관관계

# 'survived'와 'fare'(요금) 사이의 상관계수 계산
fare_corr = titanic["survived"].corr(titanic["fare"])
# 결과: 0.257307 -> 요금을 많이 낼수록 생존율이 높아지는 약한 양의 상관관계

# -- 피처 엔지니어링 --
# 나이를 구간별 카테고리로 변환하는 함수 정의
def catogoryAge(x):
    # ... (함수 내용 생략) ...
    return category

# apply 함수를 이용해 'age' 컬럼의 모든 값에 catogoryAge 함수를 적용, 결과를 'age2' 새 컬럼에 저장
titanic['age2'] = titanic["age"].apply(catogoryAge)

# 'sex' 컬럼의 문자열('male'/'female')을 숫자(1/0)로 변환
titanic["sex"] = titanic["sex"].map({"male": 1, "female": 0})

# 'sibsp'(형제/배우자)와 'parch'(부모/자녀)를 더하고 1(본인)을 추가하여 'family'(총 가족 수) 컬럼 생성
titanic["family"] = titanic["sibsp"] + titanic["parch"] + 1

# -- 히트맵 시각화 --
# 히트맵에 사용할 주요 변수들만 선택하여 새로운 데이터프레임 생성
heatmap_data = titanic[["survived", "sex", "age2", "family", "pclass", "fare"]]

colormap = plt.cm.RdBu # 색상 맵 설정 (Red-Blue)
plt.figure(figsize=(10, 8))

# 상관계수 행렬을 히트맵으로 시각화
# 연산 과정:
# 1. heatmap_data.astype(float).corr() : 선택된 데이터의 상관계수 행렬을 계산
# 2. sns.heatmap(...) : 계산된 행렬을 기반으로 히트맵을 그림
#    - annot=True : 각 셀에 상관계수 값을 표시
#    - cmap=colormap : 빨간색(양의 상관) ~ 파란색(음의 상관)으로 색상을 표현
#    - vmax=1.0 : 색상 스케일의 최대값을 1.0으로 고정
sns.heatmap(heatmap_data.astype(float).corr(), linewidths=0.1, vmax=1.0, square=True, cmap=colormap, linecolor="white", annot=True, annot_kws={"size": 10})
plt.show()
```

#### **2. 해당 설명**

이 파트는 분석의 핵심입니다. **상관 분석**은 두 변수 간의 선형적 관계의 강도와 방향을 -1에서 1 사이의 숫자로 나타냅니다. `pandas`의 `.corr()` 함수는 이를 쉽게 계산해줍니다.

**피처 엔지니어링**은 모델의 성능을 높이기 위해 데이터를 가공하는 창의적인 과정입니다.
*   **Binning (구간화):** 연속형 변수인 `age`를 `age2`라는 범주형 변수로 만들어, 단순한 나이보다 '나이대'(유아, 청소년, 성인 등)가 생존에 미치는 영향을 더 명확하게 볼 수 있도록 합니다.
*   **Mapping (매핑):** `sex`와 같은 문자열 데이터를 모델이 이해할 수 있는 숫자(0, 1)로 변환합니다.
*   **Feature Creation (파생 변수 생성):** `sibsp`와 `parch`를 합쳐 `family`라는 새로운 변수를 만듦으로써, '가족의 규모'라는 더 의미 있는 정보를 추출합니다.

마지막으로 **히트맵**은 이렇게 계산된 복잡한 상관계수 행렬을 색깔로 표현하여, 어떤 변수들이 서로 강한 관계를 맺고 있는지 직관적으로 파악하게 해주는 최고의 시각화 도구입니다.

#### **3. 응용 가능한 예제**

**"고객 이탈(Churn) 예측 모델을 위한 피처 엔지니어링"**

'가입일'과 '마지막 접속일'이라는 날짜 데이터로부터 '총 서비스 이용 기간'이라는 파생 변수를 만들고, '월 평균 구매 횟수'를 구간화하여 '충성 고객', '일반 고객', '비활성 고객'으로 나누는 등, 새로운 피처를 만들어 고객 이탈 예측 모델의 성능을 향상시킬 수 있습니다.

#### **4. 추가하고 싶은 내용 ("Correlation is not Causation")**

분석에서 가장 중요한 격언 중 하나는 **"상관관계는 인과관계가 아니다"** 입니다. 히트맵에서 `fare`(요금)와 `survived`(생존)가 양의 상관관계를 보인다고 해서 "돈을 많이 낸 것이 생존의 원인이다"라고 단정할 수 없습니다. 실제로는 요금이 비싼 `pclass` 1등급 객실이 구명보트와 가까운 곳에 위치했기 때문일 수 있습니다. 즉, `pclass`라는 제3의 변수가 둘 모두에 영향을 미친 것입니다. 상관 분석은 관계를 찾는 출발점일 뿐, 원인을 단정하는 도구는 아님을 항상 명심해야 합니다.

#### **5. 심화 내용 (다중 공선성 문제)**

히트맵은 종속 변수(`survived`)와 독립 변수들 간의 관계를 보는 데도 유용하지만, **독립 변수들끼리의 관계**를 파악하는 데도 매우 중요합니다. 만약 서로 다른 독립 변수 두 개가 매우 높은 상관관계(예: 0.9 이상)를 보인다면, 이는 **다중 공선성(Multicollinearity)** 문제가 있다는 신호입니다. 이는 회귀 모델의 안정성을 해치므로, 두 변수 중 하나를 제거하거나 주성분 분석(PCA) 같은 차원 축소 기법을 고려해야 합니다. 타이타닉 데이터에서는 `pclass`와 `fare`가 강한 음의 상관(-0.55)을 보이는데, 이는 자연스러운 현상입니다(등급이 높을수록(숫자는 작아짐) 요금은 비싸짐).