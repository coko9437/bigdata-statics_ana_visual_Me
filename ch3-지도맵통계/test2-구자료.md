
---

### **Ch3-2 코드 종합 설명**

이 코드는 서로 다른 두 개의 데이터 소스, 즉 **공공보건 의료기관 현황**과 **행정구역별 인구수**를 통합하여 **인구수 대비 의료기관의 분포**를 분석하는 것을 목표로 합니다. 데이터 분석의 가장 핵심적인 과정인 **데이터 전처리(Preprocessing)**와 **데이터 병합(Merge)**, 그리고 **시각화(Visualization)** 기술을 종합적으로 다루고 있습니다.

1.  **데이터 정제 및 표준화:** `공공보건의료기관현황.csv` 파일의 주소 데이터를 '시도'와 '군구'로 분리하고, 축약되거나 다른 명칭으로 사용된 행정구역 이름을 일관성 있게 **표준화**합니다. `행정구역_시군구_별__성별_인구수2.xlsx` 파일에서도 불필요한 공백이나 요약 행('소계')을 제거하여 데이터를 정제합니다.
2.  **데이터 병합 및 가공:** 정제된 두 데이터를 '시도군구'라는 **공통된 키(Key)**를 기준으로 병합(`merge`)하여 하나의 데이터프레임으로 만듭니다. 이후, 인구수 대비 의료기관의 비율을 나타내는 **'HS_ratio'**라는 파생 변수를 생성하여 보다 의미 있는 분석을 위한 기반을 마련합니다.
3.  **시각화:** 먼저 `matplotlib`의 **막대그래프**를 이용해 시군구별 의료기관의 절대적인 수와 인구 대비 비율을 시각적으로 탐색합니다. 최종적으로는 **블록맵**이라는 특수한 시각화 기법을 사용하여, 대한민국 지도 위에 각 행정구역별 의료기관 분포 현황을 색상의 농도로 표현함으로써 지역 간 격차를 직관적으로 파악할 수 있도록 합니다.

---

### **Part 1: 데이터 수집 및 주소 데이터 정제**

분석의 가장 첫 단계로, 원본 데이터(raw data)를 불러와 분석에 적합한 형태로 가공하는 과정입니다.

#### **1. 코드, 문법 및 개별 설명**

```python
# %%
import pandas as pd
import numpy as np

# pandas 설정: 특정 경고(chained_assignment)를 비활성화합니다.
# 데이터프레임의 일부에 값을 할당할 때 발생하는 경고를 무시하여 코드 실행을 깔끔하게 합니다.
pd.set_option("mode.chained_assignment", None)

# CSV 파일 불러오기
# - "공공보건의료기관현황.csv": 분석할 데이터 파일
# - index_col=0: 파일의 첫 번째 열을 데이터프레임의 인덱스로 사용
# - encoding="utf-8": 한글 깨짐을 방지하기 위한 인코딩 설정
# - engine="python": 파싱 엔진을 파이썬으로 지정하여 안정성을 높임
data = pd.read_csv("공공보건의료기관현황.csv", index_col=0, encoding="utf-8", engine="python")

# '주소' 컬럼에서 시도와 군구 정보 추출
# .apply(lambda v: ...): '주소' 컬럼의 각 행(v)에 대해 동일한 함수를 적용
# v.split(): 주소 문자열을 공백(' ') 기준으로 나눔 (예: "서울특별시 강남구..." -> ['서울특별시', '강남구', ...])
# [:2]: 나눠진 리스트에서 앞의 2개 요소만 선택 (시도, 군구)
# .tolist(): 결과를 파이썬 리스트 형태로 변환
# pd.DataFrame(..., columns=["시도", "군구"]): 변환된 리스트를 '시도', '군구' 컬럼을 가진 새로운 데이터프레임으로 생성
addr = pd.DataFrame(data["주소"].apply(lambda v: v.split()[:2]).tolist(), columns=["시도", "군구"])

# addr 데이터프레임의 상위 5개 행을 확인
addr.head()
# %%
# 일부 잘못 기입된 주소 데이터를 수동으로 수정
# .iloc[index]: 데이터프레임의 특정 행 번호(index)에 접근
# 예: addr.iloc[27]은 27번 행의 데이터를 의미하며, 여기에 올바른 [시도, 군구] 리스트를 할당
addr.iloc[27] = ["경상남도", "창원시"]
addr.iloc[31] = ["경상남도", "창원시"]
addr.iloc[47] = ["경상북도", "경산시"]
addr.iloc[209] = ["충청남도", "천안시"]
addr.iloc[210] = ["충청남도", "천안시"]
addr.iloc[75] = ["제주특별자치도", "제주시"] # '아란13길' 수정```

#### **2. 해당 설명**

이 파트의 핵심은 **비정형 데이터인 '주소' 문자열에서 정형 데이터인 '시도'와 '군구' 정보를 추출**하는 것입니다. `lambda`와 `split` 함수를 활용하여 주소를 공백 기준으로 자르고, 필요한 부분만 깔끔하게 분리해냈습니다. 하지만 자동화된 분리 과정에서 일부 데이터(창원시, 경산시 등)가 '시도'로 잘못 분류되는 문제가 발생했습니다. 이는 `.iloc`을 사용해 직접 해당 행의 값을 올바르게 수정하는 **수동적인 데이터 정제** 과정을 통해 해결했습니다. 데이터 분석에서는 이처럼 자동화 처리 후 예외 케이스를 직접 확인하고 보정하는 작업이 매우 흔합니다.

#### **3. 응용 가능한 예제**

**"이메일 주소에서 사용자 아이디와 도메인 분리하기"**

고객 데이터에 `user@example.com`과 같은 이메일 주소 컬럼이 있을 때, `@`를 기준으로 `split`하여 '사용자 ID'와 '도메인 주소'를 분리하고, 이를 바탕으로 어떤 이메일 서비스(gmail, naver 등)를 사용하는 고객이 많은지 분석할 수 있습니다.

#### **4. 추가하고 싶은 내용 (정규 표현식 활용)**

수동으로 `iloc`을 사용해 수정하는 방법은 데이터가 적을 때는 가능하지만, 데이터가 수만 건 이상이 되면 비효율적입니다. 이런 경우 **정규 표현식(Regular Expression)**을 사용하면 더 정교하고 자동화된 처리가 가능합니다. 예를 들어, `'시|도|시군'`으로 끝나지 않는 '시도' 컬럼의 값을 찾아내는 패턴을 만들어 오류를 더 체계적으로 탐지하고 수정할 수 있습니다.

#### **5. 심화 내용 (데이터 품질의 중요성)**

이 과정은 **데이터 품질(Data Quality)**이 분석 결과에 얼마나 큰 영향을 미치는지 보여주는 좋은 예입니다. 만약 주소 정제를 제대로 하지 않았다면, '창원시'는 '경상남도'와 다른 별개의 지역으로 집계되어 "경상남도에는 의료기관이 부족하다"는 잘못된 결론으로 이어질 수 있습니다. 분석 모델의 성능 이전에 **데이터 자체의 정확성과 일관성**을 확보하는 것이 분석 프로젝트의 성패를 좌우합니다.

---

### **Part 2: 행정구역 명칭 표준화 및 집계**

정제된 데이터를 바탕으로, 각기 다른 이름으로 불리는 행정구역 명칭을 하나로 통일하고 지역별 의료기관 수를 세는 과정입니다.

#### **1. 코드, 문법 및 개별 설명**

```python
# %%
# 표준화할 행정구역 약칭과 공식 명칭을 딕셔너리로 정의
addr_alias = {
    "경기": "경기도", "경남": "경상남도", "경북": "경상북도",
    "충북": "충청북도", "충남": "충청남도", "전북": "전북특별자치도",
    "전라북도": "전북특별자치도", "전남": "전남특별자치도", "전라남도": "전남특별자치도",
    "서울시": "서울특별시", "대전시": "대전광역시", "부산특별시": "부산광역시",
    "강원도": "강원특별자치도",
}

# '시도' 컬럼의 값을 딕셔너리를 이용해 표준화
# .apply(lambda v: addr_alias.get(v, v))
# - v: '시도' 컬럼의 각 값 (예: "경기", "서울시", "충청북도")
# - addr_alias.get(v, v):
#   - 딕셔너리(addr_alias)에서 키(v)에 해당하는 값을 찾아서 반환.
#   - 만약 키가 딕셔너리에 없으면(예: "충청북도"), 원래 값(v)을 그대로 반환.
addr["시도"] = addr["시도"].apply(lambda v: addr_alias.get(v, v))

# '시도'와 '군구'를 합쳐 '시도군구'라는 새로운 식별자(identifier) 컬럼 생성
addr["시도군구"] = addr.apply(lambda r: r["시도"] + " " + r["군구"], axis=1)

# 의료기관 수를 세기 위해 임시로 'count' 컬럼을 만들고 0을 할당 (이후 groupby에서 사용됨)
addr["count"] = 1 # 0이 아닌 1로 할당하면 groupby 후 sum()으로 쉽게 집계 가능

# '시도', '군구', '시도군구'를 기준으로 그룹화하여 'count' 컬럼의 합계를 계산
# as_index=False: 그룹화의 기준이 된 컬럼들을 인덱스가 아닌 일반 컬럼으로 유지
addr_group = pd.DataFrame(addr.groupby(["시도", "군구", "시도군구"], as_index=False).count())


# 나중에 다른 데이터와 병합하기 위해 '시도군구' 컬럼을 인덱스로 설정
addr_group = addr_group.set_index("시도군구")
```
*   **주석 수정 제안**: 코드에서는 `addr["count"] = 0` 이후 `count()`를 사용하셨는데, `addr["count"] = 1`로 설정 후 `sum()`을 사용하는 것이 더 직관적일 수 있습니다. 결과는 동일합니다. `count()`는 그룹 내의 행 개수를 세기 때문입니다.

#### **2. 해당 설명**

데이터 분석에서 **명칭 표준화**는 필수적인 과정입니다. '경기'와 '경기도'는 사람에게는 같지만 컴퓨터에게는 다른 문자열일 뿐입니다. `딕셔너리`를 활용하여 이러한 명칭들을 효율적으로 통일했습니다. 그 후, **`groupby`** 함수를 사용해 '시도군구'별로 데이터가 몇 개씩 있는지, 즉 **행정구역별 의료기관의 수를 집계**했습니다. 이 `addr_group` 데이터프레임은 우리 분석의 중요한 중간 결과물입니다. 마지막으로 `.set_index()`를 통해 '시도군구'를 인덱스로 지정했는데, 이는 나중에 인구 데이터와 병합할 때 기준점으로 사용하기 위한 전략적인 선택입니다.

#### **3. 응용 가능한 예제**

**"온라인 쇼핑몰 상품 카테고리 표준화"**

쇼핑몰에 상품을 등록할 때 '상의', 'TOP', '티셔츠' 등 판매자마다 다르게 입력한 카테고리 정보를 `딕셔너리`를 이용해 '상의'라는 하나의 표준 카테고리로 통일할 수 있습니다. 이후 `groupby`를 통해 카테고리별 상품 수나 판매량을 집계하여 분석할 수 있습니다.

---

### **Part 3: 데이터 병합(Merge) 및 비율 계산**

두 개의 서로 다른 데이터를 하나로 합치고, 분석에 필요한 새로운 지표를 만드는 과정입니다.

#### **1. 코드, 문법 및 개별 설명**

```python
# %%
# 2025년 1월 기준 행정구역별 인구수 엑셀 파일 불러오기
population = pd.read_excel("./행정구역_시군구_별__성별_인구수2.xlsx")

# 컬럼 이름을 '시도', '군구'로 변경하여 다른 데이터프레임과 형식을 맞춤
population = population.rename(columns={"행정구역(시군구)별(1)": "시도", "행정구역(시군구)별(2)": "군구"})

# '군구' 컬럼의 값들에서 양쪽 공백을 제거
# for 문을 사용하여 각 행의 '군구' 값을 .strip()으로 처리
for element in range(0, len(population)):
    population["군구"][element] = population["군구"][element].strip()

# 불필요한 요약 행('소계', '합계')을 필터링하여 제거
population = population[population.군구 != "소계"]
population = population[population.군구 != "합계"]


# '시도군구' 컬럼 생성 및 인덱스 설정 (addr_group과 동일한 방식)
population["시도군구"] = population.apply(lambda r: r["시도"] + " " + r["군구"], axis=1)
population = population.set_index("시도군구")


# %%
# 두 데이터프레임(addr_group, population)을 병합
# how="inner": 두 데이터프레임의 인덱스에 공통으로 존재하는 행만 합침 (교집합)
# left_index=True, right_index=True: 왼쪽과 오른쪽 데이터프레임 모두 인덱스를 기준으로 병합
addr_population_merge = pd.merge(addr_group, population, how="inner", left_index=True, right_index=True)

# 필요한 컬럼만 선택하고, 컬럼 이름 정리
local_Hospital_Population = addr_population_merge[["시도_x", "군구_x", "count", "총인구수 (명)"]]
local_Hospital_Population = local_Hospital_Population.rename(columns={"시도_x": "시도", "군구_x": "군구", "총인구수 (명)": "인구수"})

# '인구 10만 명당 의료기관 수'를 나타내는 'HS_ratio' 컬럼 생성
HS_count = local_Hospital_Population["count"]
local_Hospital_Population["HS_ratio"] = HS_count.div(local_Hospital_Population["인구수"], axis=0) * 100000
```

#### **2. 해당 설명**

이 파트의 핵심은 **`pd.merge`**입니다. 두 개의 독립된 정보(의료기관 수, 인구 수)를 **'시도군구'라는 공통 분모**를 통해 하나의 의미 있는 데이터로 결합했습니다. `how="inner"`(내부 조인) 옵션을 사용해 두 데이터에 모두 존재하는 지역만 분석 대상으로 삼아 데이터의 정합성을 높였습니다.

가장 중요한 부분은 **'HS_ratio'라는 파생 변수를 생성**한 것입니다. 단순히 병원 수(`count`)만 비교하면 인구가 많은 대도시가 무조건 많아 보일 수밖에 없습니다. 하지만 인구수로 나누어 비율을 계산함으로써, **인구 규모의 영향을 제거하고 지역별 의료 서비스의 밀도를 공정하게 비교**할 수 있게 되었습니다. 이는 데이터 분석에서 '정규화(Normalization)'의 좋은 예시입니다.

#### **3. 응용 가능한 예제**

**"지역별 매장 매출액과 유동인구 데이터 결합 분석"**

각 매장의 '지역'별 매출 데이터와, 통신사에서 제공하는 '지역'별 유동인구 데이터를 `merge`한 후, '유동인구 1명당 매출액'이라는 새로운 지표를 만들어 매장의 효율성을 평가하고 신규 매장 입지를 선정하는 데 활용할 수 있습니다.

---

### **Part 4: 심화 시각화 (블록맵)**

분석 결과를 지도 위에 시각화하여 지역별 차이를 한눈에 파악할 수 있도록 하는 과정입니다.

#### **1. 코드, 문법 및 개별 설명**

```python
# %%
# 블록맵 시각화에 필요한 좌표 및 경계선 데이터 로드
# data_draw_korea.csv: 각 시군구의 블록맵상 x, y 좌표 정보가 담긴 파일
data_draw_korea = pd.read_csv(path + "\\data_draw_korea.csv", index_col=0, encoding="utf-8", engine="python")

# 행정구역 명칭 표준화 (이전과 동일)
addr_aliases = {'강원도': '강원특별자치도', '전라북도': '전북특별자치도', '전라남도': '전남특별자치도'}
data_draw_korea["광역시도"] = data_draw_korea['광역시도'].apply(lambda r: addr_aliases.get(r, r))

# 병합을 위해 '시도군구' 인덱스 생성
data_draw_korea['시도군구'] = data_draw_korea.apply(lambda r: r['광역시도'] + ' ' + r['행정구역'], axis=1)
data_draw_korea = data_draw_korea.set_index("시도군구")

# 분석 데이터(local_Hospital_Population)와 지도 좌표 데이터(data_draw_korea)를 병합
# how="outer": 어느 한쪽에만 데이터가 있어도 모두 포함하여 병합 (합집합).
# 좌표는 있지만 병원 데이터가 없는 지역(NaN)도 지도에 표시하기 위함.
data_draw_korea_local_Hospital_Population = pd.merge(data_draw_korea, local_Hospital_Population, how="outer", left_index=True, right_index=True)


# %%
# 블록맵을 그리는 함수 정의
# 이 함수는 재사용 가능하도록 설계되었으며, 지도에 표시할 데이터(targetData)와 제목, 색상을 인자로 받음
def draw_blockMap(blockedMap, targetData, title, color):
    # ... (함수 내부 로직) ...
    # 핵심 로직:
    # 1. whitelabelmin: 글자 색을 흰색으로 할지 검은색으로 할지 결정하는 임계값 계산
    # 2. pivot: 1차원 데이터를 x, y 좌표 기반의 2차원 그리드 데이터로 변환
    # 3. pcolor: 2차원 데이터를 받아 각 셀의 값을 색상으로 표현 (히트맵과 유사)
    # 4. annotate: 계산된 좌표에 맞춰 각 지역의 이름을 텍스트로 표시
    # 5. BORDER_LINES: 정의된 경계선 좌표를 따라 굵은 선을 그려 광역시/도 구분
    
    # pivot 함수를 이용, 행과 열을 재배치하여 2차원 지도 데이터 생성
    mapdata = blockedMap.pivot(index='y', columns='x', values=targetData)
    
    # NaN(데이터 없는 지역) 값을 마스킹(masking)하여 그래프에 표시되지 않게 처리
    masked_mapdata = np.ma.masked_where(np.isnan(mapdata), mapdata)

    # 그래프 전체 크기 및 제목 설정
    plt.figure(figsize=(8, 13))
    plt.title(title)
    
    # pcolor 함수로 블록맵의 각 셀을 색칠. vmin, vmax로 색상 범위 고정
    plt.pcolor(masked_mapdata, vmin=min(blockedMap[targetData]), vmax=max(blockedMap[targetData]),
               cmap=color, edgecolor="#aaaaaa", linewidth=0.5)

    # 각 블록 위에 지역 이름과 수치를 주석(annotate)으로 표시
    for idx, row in blockedMap.iterrows():
        # ... (이름 표시 로직) ...
        plt.annotate(dispname, (row["x"] + 0.5, row["y"] + 0.5), ...)

    # BORDER_LINES를 이용해 광역시/도 경계선 그리기
    for path in BORDER_LINES:
        ys, xs = zip(*path)
        plt.plot(xs, ys, c="black", lw=4)

    plt.gca().invert_yaxis() # y축을 뒤집어 위쪽을 북쪽으로 맞춤
    plt.axis("off") # 불필요한 x, y축 정보 숨기기
    # ... (나머지 코드) ...
    plt.show()

# 함수 호출하여 블록맵 시각화 실행
draw_blockMap(data_draw_korea_local_Hospital_Population, "count", "행정구역별 병원 숫자", "Blues")
draw_blockMap(data_draw_korea_local_Hospital_Population, "HS_ratio", "행정구역별 인구대비 병원 비율", "Reds")
```

#### **2. 해당 설명**

이 파트에서는 **블록맵**이라는 고급 시각화 기법을 구현합니다. 블록맵은 실제 지리적 면적 대신 각 행정구역을 동일한 크기의 사각형으로 표현하여, 면적이 넓고 인구가 적은 지역이 시각적으로 과대평가되는 것을 방지합니다.

`draw_blockMap` 함수는 이 복잡한 과정을 캡슐화한 것입니다. 내부적으로 `pivot` 함수를 사용해 데이터를 2차원 격자 형태로 재구성하고, `pcolor`를 이용해 각 격자(행정구역)를 `count`나 `HS_ratio` 값에 비례하는 색상으로 칠합니다. `annotate`를 통해 각 지역의 이름을 표시하고, 미리 정의된 `BORDER_LINES`로 광역자치단체 경계를 그려 가독성을 높였습니다. 특히 분석 데이터와 지도 좌표 데이터를 병합할 때 `how="outer"`를 사용한 점이 중요합니다. 이는 병원 데이터가 없는 지역(NaN)도 지도 상에서는 빈칸으로 남겨두어 전체적인 지리적 맥락을 유지하기 위함입니다.

#### **3. 응용 가능한 예제**

**"미국 주(State)별 선거 결과 시각화"**

미국 대선 결과를 시각화할 때, 몬태나나 텍사스처럼 면적은 넓지만 선거인단 수가 상대적으로 적은 주가 지도 전체를 차지하는 왜곡이 발생할 수 있습니다. 각 주를 동일한 크기의 사각형으로 표현하는 블록맵을 사용하면, 각 주의 선거인단 수에 따른 영향력을 더 공정하고 직관적으로 보여줄 수 있습니다.

#### **4. 추가하고 싶은 내용 (インタラクティブ 시각화)**

`matplotlib`으로 생성된 지도는 정적(static)입니다. 만약 각 지역에 마우스를 올렸을 때 상세 정보(정확한 병원 수, 인구수 등)가 팝업으로 뜨게 하고 싶다면, **`folium`**이나 **`plotly`** 같은 라이브러리를 사용해 **インタラクティブ(interactive)한 지도**를 만들 수 있습니다. 이는 사용자 경험을 크게 향상시키고 더 깊은 데이터 탐색을 가능하게 합니다.

#### **5. 심화 내용 (지리정보 시각화와 왜곡)**

모든 지도 시각화는 '왜곡'을 동반합니다. 블록맵은 **'면적 왜곡'**을 해결하는 대신 **'지리적 정확성'**을 희생합니다. 실제 위치나 모양과는 차이가 생기죠. 반면, 일반적인 단계구분도(Choropleth map)는 지리적 정확성은 높지만 면적 왜곡 문제를 가집니다. 따라서 분석의 목적이 무엇인지(지역 간의 '값' 비교가 중요한가, 아니면 '지리적 위치'가 중요한가)에 따라 적절한 시각화 방법을 선택하는 능력이 중요합니다. 이 코드는 값의 비교에 더 중점을 둔 좋은 선택을 보여줍니다.