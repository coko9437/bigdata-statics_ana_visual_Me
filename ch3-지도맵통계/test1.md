
---

### **코드 종합 설명**

이 코드는 **'커피빈' 매장들의 주소 데이터를 분석 가능한 형태로 깨끗하게 다듬고, 최종적으로 각 매장의 위치를 지도 위에 시각화하는** 전체 과정을 담고 있습니다. 데이터 분석의 가장 중요한 두 가지 과정, 즉 **데이터 전처리(Data Preprocessing)**와 **시각화(Visualization)**를 모두 경험해 볼 수 있는 훌륭한 예제입니다.

1.  **데이터 준비 및 전처리:** `pandas` 라이브러리를 사용해 'CoffeeBean_before.csv' 파일을 불러옵니다. 이 데이터의 'address' 열은 '서울시 강남구...'처럼 시/도와 시/군/구가 합쳐져 있고, '서울'과 '서울특별시'처럼 표기법도 제각각입니다. 이 주소들을 행정구역 통계 데이터와 통일시키기 위해 **문자열 분리(split)**와 **표준화(standardization)** 작업을 통해 '서울특별시 강남구...' 와 같은 일관된 형식의 새 주소(`address2`)를 만듭니다.
2.  **데이터 저장:** 깨끗하게 정제된 데이터를 나중에 다시 사용하기 편하도록 'CoffeeBean_2.csv'라는 새로운 파일로 저장합니다.
3.  **지리 정보 시각화:** `folium`이라는 지도 시각화 라이브러리를 사용합니다. 먼저 간단한 지도를 만들어보는 연습을 하고, 최종적으로는 주소를 위도/경도 좌표로 변환한 데이터('Coffeebean2-완료.csv')를 불러옵니다. 이 좌표 데이터를 이용해 커피빈의 모든 매장 위치를 **지도 위에 아이콘(마커)으로 표시**하여, 매장 분포를 한눈에 파악할 수 있는 인터랙티브 지도를 완성합니다.

---

### **Part 1: 데이터 로딩 및 주소 분리 작업**

분석의 첫걸음은 원본 데이터를 불러와서 컴퓨터가 이해하기 좋은 형태로 만드는 것입니다.

#### **1. 코드, 문법 및 개별 설명**

```python
# %%
# pandas 라이브러리를 'pd'라는 별명으로 불러옵니다.
import pandas as pd

# 'CoffeeBean_before.csv' 파일을 읽어와서 CB라는 변수에 저장합니다.
# encoding="utf-8": 한글이 깨지지 않도록 설정합니다.
# index_col=0: 파일의 첫 번째 열을 데이터의 인덱스(고유 번호)로 사용합니다.
# header=0: 파일의 첫 번째 행을 컬럼(열) 이름으로 사용합니다.
CB = pd.read_csv("CoffeeBean_before.csv", encoding="utf-8", index_col=0, header=0, engine="python")

# CB 데이터의 맨 위 5줄을 미리 봅니다.
CB.head()

# %%
# 나중에 분리된 주소를 담을 비어있는 리스트(목록)를 만듭니다.
addr = []

# CB 데이터의 'address' 컬럼에 있는 모든 주소를 하나씩 꺼내 반복합니다.
for address in CB.address:
    # 각 주소(문자열)를 띄어쓰기(' ')를 기준으로 단어들로 쪼갭니다.
    # 예: "서울시 강남구 논현로 566" -> ["서울시", "강남구", "논현로", "566"]
    # 쪼갠 결과를 addr 리스트에 추가합니다.
    addr.append(str(address).split())

# addr 리스트에 결과가 잘 담겼는지 확인합니다.
print(addr)
```

#### **2. 해당 설명**

데이터 분석의 80%는 데이터를 정리하는 일이라는 말이 있을 정도로 **데이터 전처리**는 중요합니다. 위 코드는 그 첫 단계를 보여줍니다. `pandas`는 파이썬에서 엑셀처럼 표 형태의 데이터를 다룰 때 쓰는 필수 도구입니다. `read_csv` 함수로 CSV 파일을 불러와 `CB`라는 데이터 프레임(표)을 만들었습니다.

핵심은 `for` 반복문과 `.split()` 함수입니다. 'address' 컬럼의 주소는 하나의 긴 텍스트 덩어리인데, 이대로는 "서울에 매장이 몇 개지?" 같은 질문에 답하기 어렵습니다. `.split()`을 사용해 주소를 '시/도', '시/군/구', '상세주소' 등으로 나누어 다루기 쉽게 만드는 과정입니다.

#### **3. 응용 가능한 예제**

**"이메일 주소에서 아이디와 도메인 분리하기"**

고객 이메일 리스트에서 'gmail.com', 'naver.com' 등 어떤 이메일 서비스를 많이 사용하는지 분석하고 싶을 때, `email.split('@')` 코드를 사용하면 `@`를 기준으로 아이디와 도메인을 쉽게 분리하여 분석할 수 있습니다.

#### **4. 추가하고 싶은 내용 (리스트 컴프리헨션)**

`for` 반복문을 더 파이썬스럽고 간결하게 쓰는 방법으로 **리스트 컴프리헨션(List Comprehension)**이 있습니다. 위 `for`문 코드는 아래 한 줄로 똑같이 구현할 수 있습니다.

```python
# addr = [str(address).split() for address in CB.address]
```

코드가 짧아지고 가독성이 높아져서 숙련된 개발자들이 선호하는 방식입니다.

#### **5. 심화 내용 (데이터 타입의 중요성)**

코드에 `str(address)`처럼 데이터 타입을 강제로 문자열(string)로 바꾸는 부분이 있습니다. 이는 데이터에 주소가 없는 빈 값(NaN, Not a Number)이 있을 경우, `.split()` 함수를 쓸 수 없어 에러가 나는 것을 방지하기 위함입니다. 이처럼 데이터 분석 시에는 각 데이터가 숫자, 문자, 날짜 등 어떤 타입인지 항상 확인하고, 상황에 맞게 변환해주는 습관이 매우 중요합니다.

---

### **Part 2: 주소 표준화 및 데이터 병합**

제각각인 데이터를 하나의 기준으로 통일시키는, 데이터 정제의 핵심 과정입니다.

#### **1. 코드, 문법 및 개별 설명**

```python
# %%
# 표준화된 전체 주소를 담을 새로운 빈 리스트를 만듭니다.
addr2 = []

# 쪼개진 주소 목록(addr)의 길이만큼(매장 개수만큼) 반복합니다.
for i in range(len(addr)):
  # 각 주소의 첫 번째 단어(addr[i][0])가 '서울' 또는 '서울시'이면
  if addr[i][0] == "서울" or addr[i][0] == "서울시":
    # '서울특별시'로 통일해서 바꿉니다.
    addr[i][0] = "서울특별시"
  # '부산시'이면 '부산광역시'로 바꿉니다. (이하 동일)
  elif addr[i][0] == "부산시": addr[i][0] = "부산광역시"
  # ... (다른 모든 시/도에 대한 표준화 작업) ...
  elif addr[i][0] == "제주시": addr[i][0] = "제주특별자치도"

  # 표준화된 단어 리스트를 다시 띄어쓰기로 합쳐서 하나의 문자열로 만듭니다.
  # 예: ["서울특별시", "강남구", "논현로", "566"] -> "서울특별시 강남구 논현로 566"
  addr2.append(" ".join(addr[i]))

# %%
# addr2 리스트를 'address2'라는 컬럼 이름을 가진 데이터 프레임(표)으로 만듭니다.
addr2 = pd.DataFrame(addr2, columns=["address2"])

# 기존 커피빈 데이터(CB)와 방금 만든 주소 데이터(addr2)를 옆으로 합칩니다.
# axis=1은 세로(row)가 아닌 가로(column) 방향으로 합치라는 의미입니다.
CB = pd.concat([CB, addr2], axis=1)

# 합친 결과의 맨 위 5줄을 확인합니다.
CB.head()
```

#### **2. 해당 설명**

이 파트에서는 **데이터를 표준화**하는 중요한 작업을 수행합니다. 왜냐하면 컴퓨터는 '서울', '서울시', '서울특별시'를 모두 다른 데이터로 인식하기 때문입니다. 나중에 "서울특별시에는 매장이 총 몇 개인가?"를 정확히 세려면, 모든 표기를 '서울특별시'라는 하나의 이름으로 통일해야 합니다. `if/elif` 조건문을 사용해 여러 가지 표기법을 공식 행정구역 명칭으로 바꿔주는 작업을 하고 있습니다.

작업이 끝난 후에는 `.join()`을 써서 단어들을 다시 합쳐주고, `pd.DataFrame()`으로 표로 만듭니다. 마지막으로 `pd.concat()` 함수는 마치 두 개의 엑셀 시트를 옆으로 나란히 붙이는 것처럼, 기존 `CB` 데이터와 새로 만든 `addr2` 데이터를 합쳐서 분석 준비가 완료된 하나의 완성된 표로 만들어줍니다.

#### **3. 응용 가능한 예제**

**"설문조사 응답 데이터 정리하기"**

설문조사에서 '직업'을 주관식으로 물었을 때, '학생', '대학생', 'student' 등 다양한 답변이 나올 수 있습니다. 분석 전에 이런 답변들을 '학생'이라는 하나의 카테고리로 통일해야 그룹별 특징을 정확하게 분석할 수 있습니다.

#### **4. 추가하고 싶은 내용 (Dictionary 활용)**

`if/elif` 문이 너무 길어지면 코드가 지저분해 보일 수 있습니다. 이럴 때는 **딕셔너리(Dictionary)**를 사용하면 더 깔끔하게 코드를 짤 수 있습니다.

```python
# address_map = {
#     "서울": "서울특별시", "서울시": "서울특별시",
#     "부산시": "부산광역시", "인천": "인천광역시", ...
# }
# old_city = addr[i][0]
# addr[i][0] = address_map.get(old_city, old_city) # 딕셔너리에 키가 있으면 변환, 없으면 원래 값 사용
```

#### **5. 심화 내용 (데이터의 정규화)**

이렇게 데이터의 표현을 일관되게 맞추는 과정을 데이터베이스 용어로 **정규화(Normalization)**의 한 형태로 볼 수 있습니다. 정규화는 데이터의 중복을 줄이고 일관성을 유지하여 데이터의 무결성을 높이는 매우 중요한 개념입니다. 지금 한 작업은 분석의 정확도를 높이는 필수적인 과정입니다.

---

### **Part 3: 지도 시각화 (Folium)**

정제된 데이터를 이용해 사람들이 가장 쉽게 이해할 수 있는 시각 자료, 즉 지도를 만드는 과정입니다.

#### **1. 코드, 문법 및 개별 설명**

```python
# %%
# 지도 시각화 라이브러리 folium을 설치합니다. (!는 터미널 명령어 실행)
# !pip install folium
import folium

# %%
# folium을 이용해 지도를 생성합니다.
# location=[위도, 경도]: 지도의 중심이 될 좌표입니다.
# zoom_start=15: 지도 확대 레벨입니다. 숫자가 클수록 확대됩니다.
map_CB = folium.Map(location=[37.514678, 127.032052], zoom_start=15)

# 주소를 위도/경도로 변환해 둔 'Coffeebean2-완료.csv' 파일을 읽어옵니다.
CB_geoData = pd.read_csv("./Coffeebean2-완료.csv", encoding="utf-8", engine="python")

# CB_geoData 데이터 프레임의 각 행(매장 하나하나)을 반복합니다.
# .iterrows()는 데이터 프레임을 한 줄씩 순회하는 편리한 기능입니다.
for i, store in CB_geoData.iterrows():
  # 지도에 마커(위치 표시 아이콘)를 추가합니다.
  folium.Marker(
      # location: 마커를 표시할 위도(_Y), 경도(_X) 좌표
      location=[store["_Y"], store["_X"]],
      # popup: 마커를 클릭했을 때 나타날 텍스트 (매장 이름)
      popup=store["store"],
      # icon: 아이콘의 색상과 모양 설정
      icon=folium.Icon(color="red", icon="star")
  # 생성된 마커를 위에서 만든 map_CB 지도에 추가합니다.
  ).add_to(map_CB)

# 완성된 지도를 'map_커피빈_마커추가.html' 파일로 저장합니다.
map_CB.save("./map_커피빈_마커추가.html")
```

#### **2. 해당 설명**

이 파트에서는 **`folium` 라이브러리**를 사용해 지리 정보를 시각화합니다. 먼저 `folium.Map()`으로 빈 지도 캔버스를 만듭니다. 이때 `location`으로 지도의 중심을, `zoom_start`로 확대 수준을 정합니다.

가장 중요한 부분은 `for` 반복문 안의 `folium.Marker()`입니다. 이 코드는 미리 준비된 위도/경도 데이터를 한 줄씩 읽어와, 해당 위치에 `Marker`를 하나씩 찍는 역할을 합니다. `popup` 옵션으로 마커를 클릭했을 때 매장 이름이 보이게 하고, `icon` 옵션으로 마커를 예쁜 별 모양으로 꾸며주었습니다. 이 모든 마커를 `.add_to(map_CB)`로 지도에 추가한 뒤, `.save()`를 통해 우리가 웹 브라우저에서 열어볼 수 있는 **인터랙티브(Interactive) 지도** HTML 파일을 만들어냅니다.

#### **3. 응용 가능한 예제**

**"우리 동네 맛집 지도 만들기"**

내가 좋아하는 맛집들의 주소를 모아 위도/경도로 변환한 뒤, `folium`을 이용해 지도에 표시할 수 있습니다. `popup`에 메뉴나 가격 정보를 넣고, `icon`을 음식 종류별로 다르게(예: 한식은 파란색, 중식은 빨간색) 표시하면 나만의 멋진 맛집 지도를 완성할 수 있습니다.

#### **4. 추가하고 싶은 내용 (마커 클러스터링)**

만약 매장들이 너무 촘촘하게 붙어있으면 마커들이 겹쳐서 보기 힘들어집니다. 이럴 때 `folium.plugins.MarkerCluster` 기능을 사용하면, 지도를 축소했을 때 가까운 마커들이 하나의 숫자로 묶여 보이고, 지도를 확대하면 개별 마커들이 나타나게 하여 훨씬 깔끔한 지도를 만들 수 있습니다.

#### **5. 심화 내용 (지오코딩 API)**

코드 주석에는 "주소 -> 위도, 경도 변환"을 웹사이트에서 수동으로 했다고 되어 있습니다. 하지만 데이터가 수천, 수만 개라면 이는 불가능합니다. 이럴 때 **지오코딩(Geocoding) API**를 사용합니다. 구글, 카카오, 네이버 등에서 제공하는 API를 이용하면, 파이썬 코드로 주소를 보내 위도/경도 좌표를 대량으로 받아올 수 있어 전체 프로세스를 자동화할 수 있습니다. 이것이 바로 실무에서 데이터를 처리하는 방식입니다.