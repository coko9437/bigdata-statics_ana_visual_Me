
---

### **Ch4-2 코드 종합 설명**

이 코드는 `ch4-1`에서 배운 **선형 회귀 분석**의 전 과정을 **자동차 연비(MPG: Miles Per Gallon) 예측** 문제에 그대로 적용하는 실습 예제입니다. 목표는 자동차의 여러 제원(실린더 개수, 무게, 출시 연도 등)을 바탕으로 해당 자동차의 연비가 얼마나 될지를 예측하는 모델을 만드는 것입니다.

1.  **데이터 준비 및 특성 선택:** UCI 머신러닝 저장소의 `auto-mpg` 데이터를 불러옵니다. 이 코드의 중요한 특징은 **특성 선택(Feature Selection)** 과정이 포함된 점입니다. 선형 회귀 모델에 직접 사용하기 어려운 문자열 데이터(`car_name`)나, 분석의 편의를 위해 제외할 컬럼(`horsepower`, `orgin`)을 `drop` 함수를 이용해 제거하며 데이터를 정제합니다.
2.  **표준 머신러닝 프로세스 적용:** `ch4-1`과 동일하게, 데이터를 **독립 변수(X)**와 **종속 변수(Y)**로 나누고, 이를 다시 **학습용**과 **테스트용**으로 분할합니다.
3.  **모델 학습 및 평가:** `LinearRegression` 모델을 생성하여 학습용 데이터로 연비 예측 공식을 학습(`fit`)시킵니다. 이후 테스트 데이터로 예측(`predict`)을 수행하고, **MSE(평균 제곱 오차)**와 **R²(결정 계수)** 지표를 통해 모델의 예측 정확도를 객관적으로 평가합니다.
4.  **결과 해석 및 시각화:** 학습된 모델의 **회귀 계수(`coef_`)**를 분석하여 어떤 자동차 제원이 연비에 긍정적 또는 부정적인 영향을 미치는지 해석합니다. 마지막으로 `seaborn`의 `regplot`을 사용해 각 제원과 연비 간의 관계를 산점도와 회귀선으로 시각화하여, 데이터의 경향성을 직관적으로 확인하며 분석을 마무리합니다.

---

### **Part 1: 데이터 준비 및 특성 선택 (Feature Selection)**

분석에 사용할 데이터를 불러오고, 모델링에 적합하지 않거나 불필요한 정보를 제거하여 데이터를 깨끗하게 만드는 과정입니다.

#### **1. 코드, 문법 및 개별 설명**

```python
# %%
import numpy as np
import pandas as pd

# 'auto-mpg.csv' 파일을 데이터프레임으로 불러오기
# - header=0: CSV 파일의 첫 번째 줄을 컬럼 이름으로 사용하라는 의미 (기본값)
data_df = pd.read_csv("./auto-mpg.csv", header=0, engine="python")

# 데이터의 행과 열 개수 확인
print(f"data_df 의 크기 : {data_df.shape}")
data_df.head()

# %%
# 분석에 사용하지 않을 컬럼들을 제거 (특성 선택)
# - ["horsepower", "orgin", "car_name"]: 제거할 컬럼 이름 리스트
# - axis=1: 열(column)을 기준으로 제거
# - inplace=False: 원본 데이터프레임은 그대로 두고, 제거된 결과가 담긴 새로운 데이터프레임을 반환
data_df = data_df.drop(["horsepower", "orgin", "car_name"], axis=1, inplace=False)
data_df.head()

# %%
# 데이터의 기본 정보 및 결측치 확인
data_df.info()
```

#### **2. 해당 설명**

`ch4-1`과 비교했을 때, 이 파트의 가장 중요한 차이점은 **`drop` 함수를 이용한 명시적인 특성 선택(Feature Selection)**입니다. 모든 데이터가 분석에 유용한 것은 아닙니다.
*   `car_name`: 자동차 이름은 고유한 문자열 값으로, 연비를 예측하는 데 직접적인 수치 관계를 찾기 어렵습니다.
*   `orgin`: '제조국가'를 의미하는 범주형 데이터입니다. 선형 회귀는 기본적으로 숫자형 데이터만 다룰 수 있습니다. (물론, '원-핫 인코딩' 같은 기법으로 변환하면 사용할 수 있습니다.)
*   `horsepower`: '마력'을 의미하며 연비와 관련이 깊지만, 이 데이터셋에는 종종 '?'와 같은 누락된 값이 섞여 있어 데이터 정제 과정이 추가로 필요합니다. 여기서는 학습 편의를 위해 일단 제외했습니다.

이처럼 불필요하거나 모델이 처리하기 곤란한 컬럼을 제거하는 것은 데이터 전처리(preprocessing)의 중요한 첫걸음입니다.

#### **3. 응용 가능한 예제**

**"온라인 쇼핑몰 매출 예측"**

고객의 구매 데이터를 분석하여 미래 매출을 예측할 때, `고객 ID`, `주문 번호`, `상품명`과 같이 각 거래마다 고유한 값들은 예측 모델에 직접 사용하기 어렵습니다. 이러한 식별자(Identifier) 컬럼들을 `drop`으로 제거하고 `구매 금액`, `방문 횟수`, `장바구니 크기`와 같은 수치형 데이터 위주로 모델을 구성할 수 있습니다.

#### **4. 심화 내용 (범주형 데이터 처리)**

`orgin` (제조국가) 컬럼을 버리는 대신 분석에 활용하고 싶다면 어떻게 해야 할까요? 이때 **원-핫 인코딩(One-Hot Encoding)**이라는 기법을 사용합니다. `orgin` 컬럼에 'USA', 'EU', 'JAPAN'이라는 3개의 값이 있다면, 이를 'is_USA', 'is_EU', 'is_JAPAN'이라는 3개의 새로운 컬럼으로 바꾸고, 해당하는 곳에만 1을, 나머지는 0을 채우는 방식입니다. 이렇게 하면 선형 회귀 모델도 문자열 정보를 이해하고 분석에 활용할 수 있게 됩니다.

---

### **Part 2: 모델 학습 및 평가 (프로세스 복습)**

`ch4-1`에서 배운 머신러닝 표준 프로세스를 새로운 데이터에 적용하여 개념을 공고히 하는 과정입니다.

#### **1. 코드, 문법 및 개별 설명**

```python
# %%
# 1. 독립 변수(X)와 종속 변수(Y) 분리
# Y에는 예측 목표인 'mpg'(연비)를 할당
Y = data_df["mpg"]
# X에는 'mpg'를 제외한 나머지 모든 컬럼을 할당
X = data_df.drop(["mpg"], axis=1, inplace=False)

# %%
# 2. 훈련용/테스트용 데이터 분할 (70% 훈련, 30% 테스트)
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)

# %%
# 3. 모델 생성 및 학습
lr = LinearRegression()
lr.fit(X_train, Y_train)

# %%
# 4. 예측 및 평가
y_predict = lr.predict(X_test)

mse = mean_squared_error(Y_test, y_predict)
rmse = np.sqrt(mse)
r2_value = r2_score(Y_test, y_predict)

print(f"mse : {mse}, rmse : {rmse}, r2_value : {r2_value}")
# 결과 해석 예시:
# rmse: 약 3.44 -> 모델의 연비 예측이 실제 연비와 평균적으로 약 3.44 MPG 정도 차이 남.
# r2_value: 약 0.809 -> 모델이 자동차 연비 변화의 약 80.9%를 설명할 수 있음. (상당히 높은 설명력)
```

#### **2. 해당 설명**

이 파트는 `ch4-1`의 핵심 로직을 그대로 반복합니다. 이처럼 **데이터만 바꾸고 분석 코드를 재사용**하는 것은 데이터 분석에서 매우 흔한 일입니다. 이를 통해 우리는 머신러닝 프로세스가 특정 데이터에 국한되지 않는 **일반적인 문제 해결 프레임워크**임을 배울 수 있습니다.

이번 평가 결과에서 **R² 값이 약 0.809**로 매우 높게 나왔습니다. 이는 `ch4-1`의 보스턴 집값 예측 모델(R² ≈ 0.75)보다 더 성능이 좋다는 것을 의미합니다. 즉, 이 모델이 사용하는 자동차 제원들(무게, 실린더 등)이 주택 특성들보다 연비를 더 잘 설명하고 있다고 해석할 수 있습니다.

#### **3. 추가하고 싶은 내용 (random_state의 중요성)**

`train_test_split`에서 `random_state=0`으로 설정한 것은 매우 좋은 습관입니다. 만약 이 값을 설정하지 않으면 코드를 실행할 때마다 훈련/테스트 데이터가 다르게 나뉘어, 매번 평가 결과(MSE, R²)가 조금씩 달라지게 됩니다. `random_state`를 특정 숫자로 고정하면 언제, 어디서 코드를 실행하든 항상 동일한 결과를 얻을 수 있어, 모델의 성능을 일관성 있게 비교하고 분석할 수 있습니다.

---

### **Part 3: 모델 해석 및 결과 시각화**

학습된 모델이 자동차 제원과 연비 사이의 관계를 어떻게 파악했는지 들여다보고, 이를 그래프로 확인하는 과정입니다.

#### **1. 코드, 문법 및 개별 설명**

```python
# %%
# 학습된 모델의 Y절편과 회귀 계수 확인
print(f"Y 절편의 값 : {lr.intercept_}")
print(f"회귀 계수의 값 : {np.round(lr.coef_, 2)}")

# %%
# 회귀 계수를 컬럼 이름과 함께 정리하여 보기 쉽게 출력
coef = pd.Series(data=np.round(lr.coef_, 2), index=X.columns)
print(coef.sort_values(ascending=False))
# 결과 해석:
# model_year      0.76  -> 출시 연도가 1년씩 최신일수록 연비가 약 0.76 MPG 증가하는 경향.
# acceleration    0.20  -> 가속력이 1단위 높을수록 연비가 약 0.20 MPG 증가하는 경향.
# weight         -0.01  -> 차량 무게가 1단위 무거워질수록 연비가 약 0.01 MPG 감소하는 경향.
# cylinders      -0.08  -> 실린더 수가 1개 많아질수록 연비가 약 0.08 MPG 감소하는 경향.
# displacement   -0.01  -> 배기량이 1단위 클수록 연비가 약 0.01 MPG 감소하는 경향.
# (주의: weight와 displacement의 계수값이 작아 보이는 것은 변수의 스케일이 크기 때문입니다.)

# %%
# 시각화
import matplotlib.pyplot as plt
import seaborn as sns

# 2x3 형태의 격자 그림판 생성
fig, axs = plt.subplots(figsize=(16, 16), ncols=3, nrows=2)

# 시각화할 특성 리스트
x_features = ["model_year", "acceleration", "displacement", "weight", "cylinders"]
plot_color = ["r", "b", "y", "g", "r"] # 각 그래프에 적용할 색상 리스트

for i, feature in enumerate(x_features):
    row = int(i / 3)
    col = i % 3
    sns.regplot(x=feature, y="mpg", data=data_df, ax=axs[row][col], color=plot_color[i])
```

#### **2. 해당 설명**

회귀 계수(`coef_`)를 통해 우리는 모델의 '생각'을 읽을 수 있습니다.
*   **양수(+) 계수**: `model_year`, `acceleration`. 이 값들이 **높아질수록 연비도 높아지는** 경향이 있다는 것을 모델이 학습했습니다. (최신 기술이 적용된 차, 가볍게 잘 나가는 차가 연비가 좋다는 상식과 일치합니다.)
*   **음수(-) 계수**: `weight`, `cylinders`, `displacement`. 이 값들이 **높아질수록 연비는 낮아지는** 경향이 있다는 것을 학습했습니다. (무겁고, 실린더가 많고, 배기량이 큰 차가 기름을 많이 먹는다는 상식과 일치합니다.)

`regplot` 시각화는 이러한 해석을 뒷받침합니다. `weight`와 `mpg`의 관계를 보면, 점들이 뚜렷한 **우하향** 패턴을 보이며, 회귀선 역시 가파른 음의 기울기를 가집니다. 반면, `model_year`와 `mpg`는 **우상향**하는 패턴을 보여줍니다. 이처럼 시각화는 수치적인 분석 결과를 직관적으로 검증하는 강력한 도구입니다.

#### **5. 심화 내용 (변수 스케일링의 필요성)**

회귀 계수 값을 해석할 때 한 가지 주의할 점이 있습니다. `weight`의 계수는 -0.01로 매우 작아 보이지만, 실제 `weight` 값의 범위는 수천 단위(예: 2000~5000 파운드)입니다. 반면 `model_year`는 수십 단위(예: 70~82)입니다. 이처럼 각 변수(특성)가 가진 값의 범위, 즉 **스케일(scale)**이 다르면 계수 값의 크기만으로 영향력을 직접 비교하기 어렵습니다.

이 문제를 해결하기 위해 **표준화(Standardization)**나 **정규화(Normalization)** 같은 **스케일링(Scaling)** 기법을 적용하기도 합니다. 모든 변수의 스케일을 비슷한 범위(예: 평균 0, 표준편차 1)로 맞춰주면, 회귀 계수의 크기만으로 어떤 변수가 연비에 가장 큰 영향력을 미치는지 공정하게 비교할 수 있게 됩니다. 이는 더 고급 회귀 분석에서 다루는 중요한 전처리 기법입니다.