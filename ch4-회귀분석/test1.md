
---

### **회귀 분석(Regression Analysis)이란 무엇일까요?**

가장 쉽게 설명하자면, 회귀 분석은 **"데이터들 사이의 관계를 찾아내어, 하나의 변수(원인)를 가지고 다른 변수(결과)를 예측하는 방법"**입니다.

조금 더 구체적인 예시를 들어보겠습니다.

*   **"아이스크림 가게 사장님"**이 되었다고 상상해 보세요. 가게 매출을 예측하고 싶습니다. 여러 데이터를 살펴보니, **'그날의 최고 기온'**과 **'아이스크림 판매량'** 사이에 어떤 관계가 있는 것 같습니다.
    *   기온이 20도일 때: 100개 판매
    *   기온이 25도일 때: 150개 판매
    *   기온이 30도일 때: 200개 판매

이 데이터들을 점으로 찍어보면, **기온(원인)**이 올라갈수록 **판매량(결과)**도 대략 비례해서 늘어나는 패턴이 보일 겁니다.

회귀 분석은 이 점들을 가장 잘 설명할 수 있는 **하나의 선(line)**을 긋는 것과 같습니다. 이 선이 바로 두 변수 사이의 관계를 나타내는 **'모델'**이 됩니다.



이제 이 선(모델)이 있으면 무엇을 할 수 있을까요? 바로 **예측**입니다.

> **"내일 기온이 28도라는데, 아이스크림은 몇 개나 팔릴까?"**

우리가 찾은 선에 28도라는 값을 대입해보면, 대략 180개가 팔릴 것이라고 예측할 수 있습니다. 이것이 회귀 분석의 핵심입니다.

*   **독립 변수 (X)**: 예측의 원인이 되는 데이터 (예: 기온, 공부 시간, 집의 방 개수)
*   **종속 변수 (Y)**: 예측하고자 하는 결과 데이터 (예: 아이스크림 판매량, 시험 점수, 집값)

**선형 회귀(Linear Regression)**는 이 관계를 '직선'으로 표현하는 가장 기본적인 회귀 분석 방법입니다.

---

### **Ch4-1 코드 종합 설명**

이 코드는 머신러닝의 가장 대표적인 **지도 학습(Supervised Learning)** 중 하나인 **선형 회귀(Linear Regression)**를 사용하여 **보스턴 지역의 주택 가격을 예측**하는 전체 과정을 담고 있습니다. `scikit-learn`이라는 강력한 머신러닝 라이브러리를 활용하여, 데이터 과학의 표준적인 프로세스를 단계별로 실습합니다.

1.  **데이터 준비:** `scikit-learn` 라이브러리에서 더 이상 직접 제공하지 않는 보스턴 주택 가격 데이터를 외부 URL에서 안전하게 불러옵니다. 이 데이터에는 범죄율, 방의 개수 등 주택 가격에 영향을 미칠 만한 다양한 **독립 변수(특성)**와 우리가 예측하려는 **종속 변수(가격)**가 포함되어 있습니다.
2.  **데이터 분할:** 불러온 전체 데이터를 **'학습용(training set)'**과 **'테스트용(testing set)'**으로 분리합니다. 이는 마치 문제집을 풀 때 연습문제와 실전 모의고사를 나누는 것과 같습니다. 모델은 학습용 데이터로만 공부하고, 테스트용 데이터로는 실력을 평가받게 됩니다.
3.  **모델 학습:** 선형 회귀 모델(`LinearRegression`)을 생성하고, 학습용 데이터를 이용해 주택 특성(X)과 가격(Y) 사이의 관계, 즉 최적의 **회귀선(예측 공식)**을 찾도록 학습(`fit`)시킵니다.
4.  **모델 평가 및 해석:** 학습이 끝난 모델에게 테스트용 데이터를 주어 가격을 예측(`predict`)하게 합니다. 그 후, 모델의 예측값과 실제 정답(실제 가격)을 비교하여 **MSE(평균 제곱 오차)**, **R²(결정 계수)**와 같은 성능 지표를 통해 모델이 얼마나 정확한지 평가합니다. 또한, 모델이 학습한 회귀 계수(`coef_`)를 통해 어떤 특성이 주택 가격에 큰 영향을 미치는지 해석합니다.
5.  **시각화:** 마지막으로 각 특성과 주택 가격의 관계를 `seaborn`의 `regplot`을 이용해 시각화함으로써, 데이터의 경향성과 회귀선이 데이터를 얼마나 잘 표현하는지 직관적으로 확인합니다.

---

### **Part 1: 데이터 준비 및 학습/테스트 데이터 분할**

본격적인 모델링에 앞서, 데이터를 불러와 분석에 사용할 수 있는 형태로 만들고, 모델을 학습시키고 평가하기 위해 데이터를 나누는 과정입니다.

#### **1. 코드, 문법 및 개별 설명**

```python
# %%
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# %%
# scikit-learn 버전 변경으로 인해, 더 이상 load_boston() 함수를 사용할 수 없음.
# 따라서 공개된 데이터셋 URL에서 직접 데이터를 불러오는 방식으로 변경.
data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'
# 데이터의 각 컬럼(특성) 이름을 리스트로 정의
feature_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']
# 우리가 예측할 목표 변수(타겟)의 이름을 정의
target_name = 'PRICE'
# 모든 컬럼 이름을 하나의 리스트로 합침
all_column_names = feature_names + [target_name]

# pandas의 read_csv 함수로 데이터 로드
boston_df = pd.read_csv(
    data_url,
    header=None,               # 원본 파일에는 컬럼명이 없으므로 header가 없다고 명시
    delim_whitespace=True,     # 데이터가 하나 이상의 공백으로 구분되어 있음을 명시
    names=all_column_names     # 위에서 정의한 전체 컬럼명을 데이터프레임에 적용
)

boston_df.head() # 데이터가 잘 불러와졌는지 상위 5개 행 확인

# %%
# X, Y 분할: 독립 변수(X)와 종속 변수(Y)를 나눔
# 종속 변수 Y에는 예측 목표인 'PRICE' 컬럼을 할당
Y = boston_df["PRICE"]
# 독립 변수 X에는 'PRICE' 컬럼을 제외한 나머지 모든 컬럼을 할당
# - axis=1: 컬럼을 기준으로 삭제하라는 의미
# - inplace=False: 원본 boston_df 데이터프레임을 변경하지 않고, 결과를 새로운 변수 X에 저장 (기본값)
X = boston_df.drop(["PRICE"], axis=1, inplace=False)

# %%
# 훈련용(학습용), 테스트용 데이터 분리
# train_test_split 함수: 데이터를 자동으로 섞어서 비율에 맞게 나눠줌
# - X, Y: 나눌 독립 변수와 종속 변수 데이터
# - test_size=0.3: 전체 데이터 중 30%를 테스트용으로, 나머지 70%를 훈련용으로 사용
# - random_state=156: 데이터를 나눌 때 사용하는 난수 생성 시드. 이 값을 고정하면 코드를 다시 실행해도 항상 똑같은 방식으로 데이터가 나뉨 (결과 재현성을 위해 중요)
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=156)
```

#### **2. 해당 설명**

이 파트의 핵심은 **`train_test_split`**입니다. 머신러닝 모델의 성능을 공정하게 평가하려면, 모델이 **한 번도 본 적 없는 새로운 데이터**로 시험을 치러야 합니다. 만약 모델이 공부한 데이터(훈련용)로 시험까지 본다면, 단순히 답을 외워서 100점을 맞는 것과 같아서 실제 예측 능력을 알 수 없습니다. 이를 **과적합(Overfitting)**이라고 합니다. `train_test_split`은 데이터를 훈련용(70%)과 테스트용(30%)으로 명확히 분리하여, 모델이 훈련용 데이터로만 학습하고 테스트용 데이터로는 오직 평가만 받도록 환경을 만들어주는 필수적인 함수입니다.

#### **3. 응용 가능한 예제**

**"고객 이탈 예측 모델링"**

고객의 서비스 이용 기간, 월평균 결제액, 로그인 횟수 등의 데이터(X)와 이탈 여부(Y) 데이터가 있을 때, `train_test_split`을 이용해 데이터를 나누고, 훈련 데이터로 '어떤 고객이 이탈하는가'의 패턴을 학습시킨 뒤, 테스트 데이터로 모델이 새로운 고객의 이탈 가능성을 얼마나 잘 예측하는지 평가할 수 있습니다.

---

### **Part 2: 모델 학습, 예측 및 성능 평가**

준비된 데이터를 이용해 모델을 만들고, 모델이 얼마나 뛰어난지 수치로 확인하는 과정입니다.

#### **1. 코드, 문법 및 개별 설명**

```python
# %%
# 1. 모델 생성
# LinearRegression 클래스의 인스턴스(객체)를 생성.
# 아직은 아무것도 학습하지 않은 '빈' 모델 상태.
lr = LinearRegression()

# %%
# 2. 모델 학습 (훈련)
# .fit(X_train, Y_train): 훈련용 데이터(X_train, Y_train)를 모델에 주입하여 학습시킴.
# 이 과정을 통해 모델(lr)은 X_train과 Y_train 사이의 관계(최적의 회귀선)를 내부적으로 계산하고 기억하게 됨.
lr.fit(X_train, Y_train)

# %%
# 3. 예측
# .predict(X_test): 학습이 완료된 모델(lr)에게 테스트용 독립 변수(X_test)를 주고,
# 그에 해당하는 종속 변수(가격)를 예측하라고 명령함.
# 예측된 가격들은 y_predict 변수에 저장됨.
y_predict = lr.predict(X_test)

# %%
# 4. 성능 평가
# mean_squared_error(Y_test, y_predict): 실제 정답(Y_test)과 모델의 예측값(y_predict)을 비교하여 MSE 계산
mse = mean_squared_error(Y_test, y_predict)
# RMSE는 MSE에 제곱근을 취한 값. np.sqrt() 함수 사용.
# MSE는 오류를 제곱했기 때문에 단위가 커지는데, RMSE는 단위를 원래대로 돌려주어 해석이 더 쉬움.
rmse = np.sqrt(mse)

# r2_score(Y_test, y_predict): 실제 정답과 예측값을 이용해 R²(결정 계수) 계산
r2_value = r2_score(Y_test, y_predict)

# 평가 지표 출력
print(f"mse : {mse}, rmse : {rmse}, r2_value : {r2_value}")
# 결과 해석 예시:
# rmse: 약 4.15 -> 모델의 예측이 평균적으로 실제 가격에서 약 $4,150 정도 벗어남을 의미 (가격 단위가 $1000 이므로)
# r2_value: 약 0.75 -> 모델이 주택 가격 변동의 약 75%를 설명할 수 있음을 의미. (나쁘지 않은 성능)
```

#### **2. 해당 설명**

이 파트에서는 `scikit-learn`의 간결한 사용법 `fit`(학습)과 `predict`(예측)를 볼 수 있습니다. `lr.fit()`은 모델이 "공부"하는 과정이며, 이 한 줄의 코드가 내부적으로는 복잡한 수학적 계산(최소제곱법 등)을 통해 최적의 회귀선을 찾습니다. `lr.predict()`는 공부를 마친 모델이 "시험"을 치르는 과정입니다.

핵심은 **성능 평가 지표**를 올바르게 해석하는 것입니다.
*   **MSE / RMSE**: **오차의 크기**를 나타냅니다. 값이 **작을수록** 모델의 예측이 실제 값에 가깝다는 뜻이므로 좋은 모델입니다.
*   **R²**: 모델이 데이터의 변동성을 **얼마나 잘 설명하는지**를 나타내는 지표입니다. 0에서 1 사이의 값을 가지며, **1에 가까울수록** 모델이 데이터를 완벽하게 설명한다는 의미입니다. 일반적으로 R² 값이 높을수록 좋은 모델로 평가합니다.

#### **3. 추가하고 싶은 내용 (모델 평가의 중요성)**

모델을 만들고 나서 평가를 하지 않는 것은, 공부만 하고 시험을 보지 않는 것과 같습니다. 내가 만든 모델이 쓸모 있는지, 개선이 필요한지 판단하는 유일한 방법은 객관적인 평가 지표를 확인하는 것입니다. 만약 R² 값이 너무 낮게 나왔다면(예: 0.3), 데이터 전처리가 부족했거나, 선형 회귀가 아닌 더 복잡한 모델이 필요하다는 신호일 수 있습니다.

---

### **Part 3: 모델 해석 및 결과 시각화**

모델이 학습한 결과를 들여다보고, 어떤 변수가 예측에 중요한 역할을 했는지 파악하며, 이를 시각적으로 확인하는 과정입니다.

#### **1. 코드, 문법 및 개별 설명**

```python
# %%
# 학습된 모델의 y절편(intercept)과 회귀 계수(coefficients) 확인
# lr.intercept_: 회귀선이 y축과 만나는 점. 모든 독립 변수(X)가 0일 때의 예측값.
print(f"Y 절편의 값 : {lr.intercept_}")
# lr.coef_: 각 독립 변수(X)가 1단위 증가할 때마다 종속 변수(Y)가 얼마나 변하는지를 나타내는 기울기 값.
# 각 특성(CRIM, ZN, ...)에 대한 계수값이 순서대로 배열에 담겨 있음.
print(f"회귀 계수의 값 : {np.round(lr.coef_, 1)}")

# %%
# 회귀 계수를 보기 쉽게 pandas Series로 변환
# - data=...: Series의 값으로 회귀 계수 배열을 사용
# - index=X.columns: 각 계수의 이름으로 원래의 컬럼명(CRIM, ZN 등)을 사용
coef = pd.Series(data=np.round(lr.coef_, 2), index=X.columns)
# .sort_values(ascending=False): 계수값을 기준으로 내림차순 정렬하여 어떤 특성이 가장 큰 영향을 미치는지 확인
coef.sort_values(ascending=False)
# 결과 해석:
# RM(방 개수)의 계수가 3.98로 가장 큼 -> 방이 하나 늘어날 때마다 가격이 약 $3,980 오르는 경향.
# LSTAT(하위 계층 비율)의 계수가 -0.57로 가장 작음 -> 하위 계층 비율이 1% 늘어날 때마다 가격이 약 $570 떨어지는 경향.

# %%
# 시각화
import matplotlib.pyplot as plt
import seaborn as sns

# 5x3 형태의 격자(grid) 그림판(figure) 생성. 전체 크기 16x16
fig, axs = plt.subplots(figsize=(16, 16), ncols=3, nrows=5)

# X의 각 특성(feature) 이름을 리스트로 저장
x_features = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']

# enumerate 함수를 이용해 각 특성과 그 인덱스(i)를 순회
for i, feature in enumerate(x_features):
    row = int(i / 3) # 현재 특성을 그릴 행(row) 위치 계산
    col = i % 3      # 현재 특성을 그릴 열(col) 위치 계산
    
    # seaborn의 regplot 함수로 산점도와 회귀선을 동시에 그림
    # - x=feature, y="PRICE": x축과 y축에 사용할 데이터 컬럼 지정
    # - data=boston_df: 사용할 전체 데이터프레임
    # - ax=axs[row][col]: 그림을 그릴 위치를 위에서 계산한 격자 위치로 지정
    sns.regplot(x=feature, y="PRICE", data=boston_df, ax=axs[row][col])
```

#### **2. 해당 설명**

이 파트의 핵심은 모델을 **'블랙박스'**가 아닌 **'화이트박스'**로 만드는 것입니다. `lr.coef_` 값을 통해 우리는 모델이 "왜" 그런 예측을 했는지 이해할 수 있습니다. 예를 들어, `RM`(방 개수)의 계수가 큰 양수라는 것은 모델이 **"방이 많을수록 집값이 비싸다"**는 규칙을 학습했음을 의미합니다. 반대로 `LSTAT`(하위 계층 비율)의 계수가 음수라는 것은 **"하위 계층 비율이 높을수록 집값이 싸다"**는 규칙을 학습했음을 보여줍니다.

**`seaborn`의 `regplot`**은 이러한 관계를 시각적으로 완벽하게 보여줍니다. 각 점은 실제 데이터이고, 그 위를 가로지르는 선은 모델이 학습한 선형 관계(회귀선)입니다. RM 그래프는 우상향하는 직선을, LSTAT 그래프는 우하향하는 직선을 보여주며, 이는 우리가 계수 값으로 해석한 내용과 정확히 일치합니다.

#### **3. 심화 내용 (다중공선성 및 규제)**

이 모델에서 주의할 점은 **다중공선성(Multicollinearity)**입니다. 이는 독립 변수들끼리 서로 강한 상관관계를 가지는 현상으로, 이 경우 회귀 계수(`coef_`)의 값이 불안정해져 해석에 오류가 생길 수 있습니다. 예를 들어, '고속도로 접근성(RAD)'과 '재산세율(TAX)'은 서로 관련이 높을 수 있습니다.

이런 문제를 해결하기 위해 **릿지(Ridge)**나 **라쏘(Lasso)**와 같은 **규제(Regularization)**가 적용된 선형 회귀 모델을 사용하기도 합니다. 이 모델들은 너무 큰 회귀 계수 값에 페널티를 부과하여 모델을 더 안정적으로 만들고 과적합을 방지하는 효과가 있습니다. 이것이 회귀 분석을 더 깊이 공부할 때 배우게 될 다음 단계입니다.