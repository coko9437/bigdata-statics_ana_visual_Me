
---

### **Ch7 미니 코드 종합 설명**

이 코드는 Ch7-1에서 공들여 만들고 저장해 둔 **감성 분석 모델과 TF-IDF 변환기를 재사용**하여, 텍스트 마이닝 파이프라인의 **'활용' 단계**를 집중적으로 보여줍니다. 핵심은 이미 학습된 자산(모델)을 불러와 새로운 문제를 해결하고, 그 결과로부터 추가적인 비즈니스 인사이트를 도출하는 것입니다.

1.  **사전 학습 모델 로드 및 실시간 예측:** `pickle`로 저장된 `TF-IDF` 모델과 최적화된 `로지스틱 회귀` 감성 분석 모델을 메모리로 불러옵니다. 이를 이용해 사용자가 터미널에 직접 입력하는 문장의 긍정/부정을 실시간으로 판별하는 간단한 애플리케이션을 구현합니다. 이는 모델이 어떻게 실제 서비스에 통합될 수 있는지 보여주는 예시입니다.
2.  **새로운 도메인 데이터에 모델 적용:** 영화 리뷰로 학습된 감성 분석 모델을 전혀 다른 주제인 **코로나 관련 뉴스 데이터**에 적용합니다. 각 뉴스 기사의 제목과 본문을 분석하여 긍정적인지, 부정적인지 자동으로 라벨링합니다.
3.  **감성별 키워드 추출 및 시각화:** 감성 분석 결과를 바탕으로 뉴스 기사를 '긍정 뉴스 그룹'과 '부정 뉴스 그룹'으로 분리합니다. 각 그룹에서 **핵심 명사(키워드)**를 추출하고, TF-IDF 점수를 기반으로 어떤 단어들이 각 감성을 대표하는지 분석합니다. 이 결과를 **막대그래프**로 시각화하여 "긍정 뉴스는 주로 어떤 단어를 포함하는가?", "부정 뉴스는 어떤 단어를 포함하는가?"에 대한 직관적인 답을 찾습니다.
4.  **토픽 모델링으로 주제 발견:** 감성 분석과는 별개로, 전체 코로나 뉴스 데이터에 어떤 **잠재적인 주제(토픽)**들이 숨어있는지 **LDA(Latent Dirichlet Allocation)** 알고리즘을 통해 분석합니다. `pyLDAvis`를 통해 토픽 간의 관계와 각 토픽을 구성하는 핵심 단어들을 시각화하여, 데이터 전체를 관통하는 거시적인 트렌드와 주제를 파악합니다.

---

### **Part 1: 사전 학습 모델 로드 및 실시간 예측**

오랜 시간 학습시킨 모델을 다시 학습할 필요 없이, 저장된 파일을 불러와 즉시 사용하는 단계입니다.

#### **1. 코드, 문법 및 개별 설명**

```python
# %%
import pickle
import re
# ... (okt, okt_tokenizer 정의는 이전과 동일) ...

# --- 1. 저장된 모델 불러오기 ---
# 'rb'는 'read binary' 모드를 의미
# TF-IDF 변환기 로드
with open("./tfidf_model.pkl", "rb") as file:
    tfidf = pickle.load(file)
# 감성 분석 분류기 로드
with open("./SA_lr_best.pkl", "rb") as file:
    SA_lr_best = pickle.load(file)

# --- 2. 사용자 입력 및 전처리 ---
st = input("감성 분석하기위한 문장을 입력 해주세요: ")
# 정규표현식으로 한글만 추출
st = re.compile(r"[ㄱ - | 가-힣]+").findall(st)
# 토큰화된 단어들을 다시 하나의 문장으로 합침 (transform 함수는 문자열 리스트를 입력으로 받음)
st = [" ".join(st)]

# --- 3. 예측 수행 ---
# 불러온 tfidf 변환기를 사용해 입력 문장을 벡터화 (주의: .transform() 사용)
st_tfidf = tfidf.transform(st)
# 불러온 감성 분석 모델로 예측
st_predict = SA_lr_best.predict(st_tfidf)

# --- 4. 결과 출력 ---
if (st_predict == 0):
    print(st, " -> 부정")
else:
    print(st, " -> 긍정")
```

#### **2. 해당 설명**

이 파트는 **머신러닝 모델의 생명주기**에서 '배포(Deployment)'와 '추론(Inference)' 단계를 아주 간단하게 보여줍니다.

*   **모델 지속성(Persistence):** `pickle`을 사용해 학습된 모델 객체를 파일로 저장하고 다시 불러오는 것은 매우 중요한 개념입니다. 수 시간 걸리는 모델 학습을 매번 반복할 필요 없이, 학습된 결과물을 저장해두면 언제든지 수 초 안에 불러와 예측에 사용할 수 있습니다.
*   **일관된 파이프라인:** 새로운 문장을 예측할 때, **반드시 모델을 학습시켰던 `tfidf` 변환기를 그대로 사용**해야 합니다. 만약 새로운 변환기를 만들면 단어 사전과 IDF값이 모두 달라져 올바른 예측을 할 수 없습니다. `tfidf.transform(st)`는 기존에 학습된 단어 사전을 기준으로 입력 문장을 숫자 벡터로 변환하는 역할을 합니다.

이 코드는 사용자의 입력을 받아 실시간으로 결과를 반환하는, 모든 AI 서비스의 가장 기본적인 형태를 보여줍니다.

#### **3. 응용 가능한 예제**

**"이메일 스팸 필터"**

미리 수백만 건의 이메일로 학습시킨 '스팸 분류 모델'을 로드한 뒤, 새로 들어오는 이메일의 내용을 벡터화하여 스팸인지 아닌지 실시간으로 예측하고 '스팸 메일함'으로 자동 분류하는 기능에 이 로직이 그대로 사용됩니다.

#### **4. 추가하고 싶은 내용 (모델 버전 관리)**

실제 운영 환경에서는 모델이 계속 업데이트되므로 `SA_lr_best_v1.0.pkl`, `SA_lr_best_v1.1.pkl`과 같이 모델 파일에 버전을 명시하여 관리하는 것이 중요합니다. 또한, 모델을 만들 때 사용했던 라이브러리 버전(scikit-learn, konlpy 등)도 함께 기록해두어야 나중에 호환성 문제 없이 모델을 불러올 수 있습니다.

#### **5. 심화 내용 (API 서버 구축)**

이 로직을 **Flask**나 **FastAPI** 같은 웹 프레임워크와 결합하면, 다른 프로그램들이 HTTP 요청을 통해 문장을 보내고 감성 분석 결과를 JSON 형태로 받아갈 수 있는 **API 서버**를 만들 수 있습니다. 이는 다른 서비스와 모델을 연동하는 표준적인 방법입니다.

---

### **Part 2: 새로운 데이터에 감성 분석 적용 및 키워드 추출**

학습된 모델을 활용하여 새로운 데이터를 분석하고, 그 결과로부터 숨겨진 패턴을 찾아내는 과정입니다.

#### **1. 코드, 문법 및 개별 설명**

```python
# %%
# ... (코로나 뉴스 데이터 로드 및 전처리) ...

# --- 1. 감성 예측 및 결과 저장 ---
# 불러온 tfidf와 SA_lr_best 모델을 사용해 뉴스 제목/본문의 감성을 예측
data_title_tfidf = tfidf.transform(data_df["title"])
data_df["title_label"] = SA_lr_best.predict(data_title_tfidf)

data_description_tfidf = tfidf.transform(data_df["description"])
data_df["description_label"] = SA_lr_best.predict(data_description_tfidf)

# --- 2. 긍정/부정 그룹 분리 ---
# ... (for 루프를 사용해 description_label이 0이면 NEG_data_df, 1이면 POS_data_df에 추가) ...

# --- 3. 긍정/부정 그룹별 키워드(명사) 추출 ---
POS_description = POS_data_df['description']
POS_description_noun_tk = []
for d in POS_description:
    # okt.nouns(): 문장에서 명사만 리스트 형태로 추출
    POS_description_noun_tk.append(okt.nouns(d))

# 한 글자 명사 제거 및 다시 문장 형태로 join
# ... (이전 코드와 동일) ...

# --- 4. 그룹 내 단어 중요도 분석 및 시각화 ---
# 긍정 뉴스 명사들만으로 새로운 TF-IDF 변환기 생성 및 학습
POS_tfidf = TfidfVectorizer(tokenizer=okt_tokenizer, min_df=2)
POS_dtm = POS_tfidf.fit_transform(POS_description_noun_join)

# 각 단어의 TF-IDF 점수 합계를 계산하여 중요도 순으로 정렬
POS_vocab = dict()
for idx, word in enumerate(POS_tfidf.get_feature_names_out()):
    POS_vocab[word] = POS_dtm.getcol(idx).sum()
POS_words = sorted(POS_vocab.items(), key=lambda x: x[1], reverse=True)

# 상위 15개 단어를 막대그래프로 시각화
# ... (matplotlib 코드) ...
# (부정 뉴스에 대해서도 동일한 과정 반복)
```

#### **2. 해당 설명**

이 파트는 단순한 예측을 넘어 **데이터 기반 의사결정**으로 나아가는 과정을 보여줍니다.

*   **모델의 재활용성:** 영화 리뷰라는 특정 도메인에서 학습된 언어의 긍정/부정 패턴이 뉴스라는 새로운 도메인에서도 어느 정도 유효하게 작동함을 보여줍니다.
*   **분석의 심화 (Post-analysis):** 감성 분석으로 1차 분류를 수행한 뒤, 그 결과를 바탕으로 2차 분석을 진행하는 것이 핵심입니다. **"왜 이 뉴스들이 긍정(또는 부정)으로 분류되었을까?"** 라는 질문에 답하기 위해, 각 그룹 내에서 **가장 중요한 명사 키워드**를 추출합니다.
*   **키워드 추출 로직:** 여기서 주목할 점은, 긍정/부정 뉴스 그룹 내의 키워드 중요도를 파악하기 위해 **별도의 `TfidfVectorizer`를 새로 생성**했다는 것입니다. 이는 "긍정 뉴스들 사이에서 상대적으로 더 중요한 단어"를 찾기 위함입니다. 예를 들어 '코로나'는 긍정/부정 뉴스 모두에 흔하게 나오겠지만, '백신'이나 '일상'은 긍정 뉴스 그룹 내에서 더 두드러지는 키워드일 수 있습니다. 이 방법을 통해 각 감성 그룹의 핵심적인 특징을 명확하게 파악할 수 있습니다.
*   **시각화를 통한 인사이트:** 막대그래프는 분석 결과를 가장 직관적으로 전달하는 도구입니다. `긍정 뉴스의 단어` 차트와 `부정 뉴스의 단어` 차트를 비교함으로써, 대중의 관심사가 어떤 키워드를 중심으로 긍정적 또는 부정적 여론을 형성하는지 한눈에 파악할 수 있습니다.

#### **3. 응용 가능한 예제**

**"호텔 리뷰 분석을 통한 서비스 개선"**

호텔 이용 후기를 긍정/부정으로 분류한 뒤, 부정 리뷰 그룹에서 자주 등장하는 명사 키워드(예: '소음', '청결', '주차', '직원')를 추출하고 시각화합니다. 이를 통해 고객들이 주로 어떤 점에서 불만족하는지 파악하고 서비스 개선의 우선순위를 정할 수 있습니다.

#### **4. 추가하고 싶은 내용 (Word Cloud)**

막대그래프 외에도 **워드 클라우드(Word Cloud)**는 키워드의 중요도를 시각적으로 표현하는 데 매우 효과적인 방법입니다. 단어의 중요도(TF-IDF 점수 합계)에 따라 글자의 크기를 다르게 표시하여 핵심 키워드를 더욱 강조할 수 있습니다.

#### **5. 심화 내용 (감성 점수 활용)**

로지스틱 회귀 모델은 `predict()`(0 또는 1 예측) 외에 `predict_proba()` 함수를 제공합니다. 이 함수는 각 클래스(긍정/부정)에 속할 확률을 반환합니다. (예: `[0.1, 0.9]` -> 부정이 10%, 긍정이 90% 확률). 이 확률 값을 '감성 점수'로 활용하면, 단순히 긍정/부정으로 나누는 것을 넘어 "매우 강한 긍정", "약한 긍정"과 같이 감성의 강도까지 분석하는 더 세밀한 접근이 가능합니다.

---

### **Part 3: 토픽 모델링(LDA)을 통한 주제 발견**

데이터의 감성적 측면을 넘어, 내용적 측면에서 어떤 주제들이 논의되고 있는지 분석하는 단계입니다.

#### **1. 코드, 문법 및 개별 설명**

```python
# %%
import gensim
import gensim.corpora as corpora
import pyLDAvis.gensim
import pickle

# --- 1. LDA용 데이터 준비 ---
description = data_df['description']
# 뉴스 본문에서 명사 추출 (한 글자 단어 제외)
# ... (코드 생략, 이전과 동일) ...

# --- 2. 사전 및 코퍼스 생성 ---
# 단어 -> ID 맵핑
dictionary = corpora.Dictionary(description_noun_tk2)
# 문서 -> (단어ID, 빈도) 리스트로 변환
corpus = [dictionary.doc2bow(word) for word in description_noun_tk2]

# --- 3. LDA 모델 학습 ---
k = 4  # 찾고자 하는 토픽의 개수를 4로 설정
lda_model = gensim.models.ldamulticore.LdaMulticore(corpus, num_topics=k, id2word=dictionary, ...)
print(lda_model.print_topics(num_topics=k, num_words=15))

# --- 4. LDA 모델 저장 및 시각화 ---
# 학습된 LDA 모델도 재사용을 위해 저장
with open("lda_model.pkl", "wb") as f:
    pickle.dump(lda_model, f)

# pyLDAvis를 이용해 인터랙티브 시각화 준비
lda_vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)
# Jupyter 환경에서 시각화 결과 표시
pyLDAvis.display(lda_vis)
```

#### **2. 해당 설명**

이 파트는 Ch7-1의 토픽 모델링 부분과 동일한 로직을 수행하며, 감성 분석과는 다른 관점에서 데이터 전체를 조망합니다.

*   **보완적 분석:** 감성 분석이 "뉴스가 긍정적인가, 부정적인가?"라는 **'어조(Tone)'**를 분석했다면, 토픽 모델링은 "무슨 내용에 대해 이야기하고 있는가?"라는 **'주제(Subject)'**를 분석합니다. 이 두 가지는 서로 보완적인 정보를 제공합니다.
*   **주제 발견:** 분석가는 `print_topics` 결과와 `pyLDAvis` 시각화를 보고 각 토픽을 구성하는 핵심 단어들을 기반으로 주제를 해석합니다. 예를 들어, 다음과 같이 해석할 수 있습니다.
    *   **토픽 0:** '백신', '접종', '효과', '안전성' -> **백신 효과 및 안전성** 관련 주제
    *   **토픽 1:** '확진자', '발생', '수도권', '거리두기' -> **국내 확진자 현황 및 방역 조치** 관련 주제
    *   **토픽 2:** '경제', '지원', '소상공인', '피해' -> **코로나로 인한 경제적 영향 및 지원책** 관련 주제
*   **`pyLDAvis`의 가치:** 수많은 기사를 읽지 않고도, `pyLDAvis`의 인터랙티브한 시각화 자료를 통해 (1) 전체 뉴스에서 어떤 주제들이 주로 다뤄지는지 (원의 크기), (2) 주제들이 서로 얼마나 관련 있는지 (원의 거리), (3) 각 주제는 어떤 핵심 단어들로 구성되는지 (우측 막대그래프)를 한눈에 파악할 수 있습니다. 이는 데이터에 대한 거시적인 이해를 돕는 매우 강력한 도구입니다.

#### **3. 응용 가능한 예제**

**"고객 문의 데이터 분석"**

콜센터나 Q&A 게시판에 접수된 수천 건의 고객 문의 텍스트에 LDA를 적용하여, 고객들이 주로 어떤 주제(예: '결제/환불 문의', '제품 기능 문의', '배송 문의', '계정 문제')에 대해 질문하는지 자동으로 그룹화하고 각 주제의 비중을 파악할 수 있습니다. 이를 통해 FAQ를 개선하거나 상담 인력을 효율적으로 배분하는 등의 의사결정을 내릴 수 있습니다.

#### **4. 추가하고 싶은 내용 (토픽과 감성의 결합 분석)**

한 단계 더 나아가, 각 문서가 어떤 토픽에 속하는지 예측한 결과와 이전에 수행한 감성 분석 결과를 결합할 수 있습니다. 예를 들어, '백신 효과 및 안전성' 토픽에 속하는 뉴스들의 평균 감성 점수는 높은 반면, '경제적 영향' 토픽에 속하는 뉴스들의 평균 감성 점수는 낮게 나타나는 경향을 발견할 수 있습니다. 이러한 결합 분석은 훨씬 더 깊이 있는 인사이트를 제공합니다.

#### **5. 심화 내용 (동적 토픽 모델링, Dynamic Topic Modeling)**

뉴스 데이터에 '시간' 정보가 있다면, **동적 토픽 모델링**을 적용하여 시간에 따라 각 토픽의 비중이 어떻게 변화했는지 추적할 수 있습니다. 예를 들어, '초기에는 '바이러스 전파' 토픽이 지배적이었지만, 시간이 지나면서 '백신 개발' 토픽의 비중이 커지고, 최근에는 '일상 회복' 토픽이 부상하는' 것과 같은 트렌드를 분석할 수 있습니다.